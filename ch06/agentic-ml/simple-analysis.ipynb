{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.types.responses import (ResponseTextDeltaEvent, ResponseFunctionCallArgumentsDeltaEvent)\n",
    "from agents import Agent, Runner\n",
    "from agents import function_tool\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API \ud0a4\ub294 \ud658\uacbd \ubcc0\uc218\ub85c \uc124\uc815\ud558\uc138\uc694. \uc18c\uc2a4 \ucf54\ub4dc\uc5d0 \ud558\ub4dc\ucf54\ub529\ud558\uc9c0 \ub9c8\uc138\uc694.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_storage = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def kaggle_list_datasets(keyword: str) -> str:\n",
    "    \n",
    "    \"\"\"\n",
    "    \uac80\uc0c9 \ucffc\ub9ac\uc5d0 \ub9de\ub294 Kaggle \ub370\uc774\ud130\uc14b \ubaa9\ub85d\uc744 \uc870\ud68c\ud569\ub2c8\ub2e4\n",
    "    \"\"\"\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "    try:\n",
    "        # \ub370\uc774\ud130\uc14b \uac80\uc0c9\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        datasets = api.dataset_list(search=keyword, sort_by=\"hottest\")\n",
    "        \n",
    "        result = []\n",
    "        count = 0\n",
    "        for dataset in datasets:\n",
    "            if count >= 10:\n",
    "                break\n",
    "            dataset_info = {\n",
    "                \"ref\": dataset.ref,  # owner/dataset-name \ud615\uc2dd\n",
    "                \"title\": dataset.title,\n",
    "            }\n",
    "            \n",
    "            # \uc548\uc804\ud558\uac8c \uc18d\uc131 \ucd94\uac00\n",
    "            if hasattr(dataset, 'size'):\n",
    "                dataset_info[\"size\"] = dataset.size\n",
    "            if hasattr(dataset, 'lastUpdated'):\n",
    "                dataset_info[\"last_updated\"] = str(dataset.lastUpdated)\n",
    "            if hasattr(dataset, 'downloadCount'):\n",
    "                dataset_info[\"download_count\"] = dataset.downloadCount\n",
    "            if hasattr(dataset, 'voteCount'):\n",
    "                dataset_info[\"vote_count\"] = dataset.voteCount\n",
    "            if hasattr(dataset, 'tags'):\n",
    "                dataset_info[\"tags\"] = dataset.tags\n",
    "            if hasattr(dataset, 'usabilityRating'):\n",
    "                dataset_info[\"usability_rating\"] = dataset.usabilityRating\n",
    "            \n",
    "            result.append(dataset_info)\n",
    "            count += 1\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"count\": len(result),\n",
    "            \"datasets\": result\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"message\": f\"\ub370\uc774\ud130\uc14b \ubaa9\ub85d \uc870\ud68c \uc2e4\ud328: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def kaggle_check_and_download_dataset(dataset_ref: str, path: str = None) -> str:\n",
    "    \"\"\"\n",
    "    \ub370\uc774\ud130\uc14b\uc774 \uc774\ubbf8 \ub2e4\uc6b4\ub85c\ub4dc\ub418\uc5b4 \uc788\ub294\uc9c0 \ud655\uc778\ud558\uace0, \uc5c6\uc73c\uba74 \ub2e4\uc6b4\ub85c\ub4dc\ud569\ub2c8\ub2e4.\n",
    "    \n",
    "    Args:\n",
    "        dataset_ref: \ub2e4\uc6b4\ub85c\ub4dc\ud560 \ub370\uc774\ud130\uc14b\uc758 \ucc38\uc870 (owner/dataset-name \ud615\uc2dd)\n",
    "        path: \ub370\uc774\ud130\uc14b\uc744 \uc800\uc7a5\ud560 \uacbd\ub85c (\uae30\ubcf8\uac12: None, Kaggle API \uae30\ubcf8 \uacbd\ub85c \uc0ac\uc6a9)\n",
    "    \n",
    "    Returns:\n",
    "        \ub370\uc774\ud130\uc14b \uc0c1\ud0dc \ubc0f \uacbd\ub85c \uc815\ubcf4\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "    \n",
    "    try:\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        \n",
    "        # \ub370\uc774\ud130\uc14b \uc815\ubcf4 \ucd94\ucd9c\n",
    "        owner, dataset_name = dataset_ref.split('/')\n",
    "        \n",
    "        # \uae30\ubcf8 Kaggle \ub2e4\uc6b4\ub85c\ub4dc \uacbd\ub85c \ub610\ub294 \uc0ac\uc6a9\uc790 \uc9c0\uc815 \uacbd\ub85c\n",
    "        if path is None:\n",
    "            from pathlib import Path\n",
    "            kaggle_dir = os.path.join(str(Path.home()), '.kaggle', 'datasets')\n",
    "            dataset_dir = os.path.join(kaggle_dir, owner, dataset_name)\n",
    "        else:\n",
    "            dataset_dir = os.path.join(path, owner, dataset_name)\n",
    "        \n",
    "        # \ub370\uc774\ud130\uc14b\uc774 \uc774\ubbf8 \uc874\uc7ac\ud558\ub294\uc9c0 \ud655\uc778\n",
    "        if os.path.exists(dataset_dir) and len(os.listdir(dataset_dir)) > 0:\n",
    "            # \ub370\uc774\ud130\uc14b\uc774 \uc774\ubbf8 \uc874\uc7ac\ud568\n",
    "            files = os.listdir(dataset_dir)\n",
    "            data_storage[dataset_ref] = dataset_dir\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"already_downloaded\": True,\n",
    "                \"message\": f\"\ub370\uc774\ud130\uc14b '{dataset_ref}'\ub294 \uc774\ubbf8 \ub2e4\uc6b4\ub85c\ub4dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.\",\n",
    "                \"path\": dataset_dir,\n",
    "                \"files\": files\n",
    "            }\n",
    "        else:\n",
    "            # \ub370\uc774\ud130\uc14b \ub2e4\uc6b4\ub85c\ub4dc\n",
    "            api.dataset_download_files(dataset_ref, path=path, unzip=True)\n",
    "            \n",
    "            # \ub2e4\uc6b4\ub85c\ub4dc \ud6c4 \uacbd\ub85c \ud655\uc778 \ubc0f \uc800\uc7a5\n",
    "            if path is None:\n",
    "                # \uae30\ubcf8 \uacbd\ub85c\uc5d0 \ub2e4\uc6b4\ub85c\ub4dc\ub41c \uacbd\uc6b0\n",
    "                dataset_dir = os.path.join(kaggle_dir, owner, dataset_name)\n",
    "            \n",
    "            if os.path.exists(dataset_dir):\n",
    "                files = os.listdir(dataset_dir)\n",
    "                data_storage[dataset_ref] = dataset_dir\n",
    "                \n",
    "                return {\n",
    "                    \"success\": True,\n",
    "                    \"already_downloaded\": False,\n",
    "                    \"message\": f\"\ub370\uc774\ud130\uc14b '{dataset_ref}'\ub97c \uc131\uacf5\uc801\uc73c\ub85c \ub2e4\uc6b4\ub85c\ub4dc\ud588\uc2b5\ub2c8\ub2e4.\",\n",
    "                    \"path\": dataset_dir,\n",
    "                    \"files\": files\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"message\": f\"\ub370\uc774\ud130\uc14b '{dataset_ref}'\ub97c \ub2e4\uc6b4\ub85c\ub4dc\ud588\uc9c0\ub9cc \uacbd\ub85c\ub97c \ucc3e\uc744 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4.\"\n",
    "                }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"message\": f\"\ub370\uc774\ud130\uc14b \ub2e4\uc6b4\ub85c\ub4dc \uc911 \uc624\ub958 \ubc1c\uc0dd: {str(e)}\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def kaggle_download_dataset(dataset_ref: str) -> str:\n",
    "    \"\"\"\n",
    "    Kaggle \ub370\uc774\ud130\uc14b\uc744 \ub2e4\uc6b4\ub85c\ub4dc\ud569\ub2c8\ub2e4\n",
    "    \"\"\"\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    try:\n",
    "        # Kaggle API\ub85c \ub370\uc774\ud130\uc14b \ub2e4\uc6b4\ub85c\ub4dc\n",
    "        api.dataset_download_files(dataset_ref, path=f\"datasets/{dataset_ref}/\", unzip=True)\n",
    "        import os\n",
    "        import pandas as pd\n",
    "        \n",
    "        # \ub2e4\uc6b4\ub85c\ub4dc \uc131\uacf5 \uc2dc \ucc98\ub9ac\n",
    "        dataset_path = f\"datasets/{dataset_ref}/\"\n",
    "        \n",
    "        # \ub514\ub809\ud1a0\ub9ac \ub0b4 \ud30c\uc77c \ubaa9\ub85d \uac00\uc838\uc624\uae30\n",
    "        files = os.listdir(dataset_path)\n",
    "        \n",
    "        # CSV \ud30c\uc77c \ucc3e\uae30\n",
    "        csv_files = [f for f in files if f.endswith('.csv')]\n",
    "        \n",
    "        if csv_files:\n",
    "            # \uccab \ubc88\uc9f8 CSV \ud30c\uc77c \ub85c\ub4dc\n",
    "            first_csv = os.path.join(dataset_path, csv_files[0])\n",
    "            df = pd.read_csv(first_csv)\n",
    "            \n",
    "            # \ub370\uc774\ud130 \uc800\uc7a5\uc18c\uc5d0 \uc800\uc7a5\n",
    "            data_storage[dataset_ref] = df\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"message\": f\"\ub370\uc774\ud130\uc14b \ub2e4\uc6b4\ub85c\ub4dc \ubc0f \ub85c\ub4dc \uc131\uacf5 : (\uc800\uc7a5\uc18c key : {dataset_ref})\",\n",
    "                \"file_loaded\": csv_files[0],\n",
    "                \"rows\": len(df),\n",
    "                \"columns\": len(df.columns)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"message\": f\"\ub370\uc774\ud130\uc14b \ub2e4\uc6b4\ub85c\ub4dc \uc131\uacf5\ud588\uc73c\ub098 CSV \ud30c\uc77c\uc774 \uc5c6\uc2b5\ub2c8\ub2e4: {dataset_ref}\",\n",
    "                \"files_available\": files\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"message\": f\"\ub370\uc774\ud130\uc14b \ub2e4\uc6b4\ub85c\ub4dc \uc2e4\ud328: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def load_csv_from_url(url: str, key: str) -> str:\n",
    "    import pandas as pd\n",
    "    \"\"\"\n",
    "    URL\uc5d0\uc11c CSV \ud30c\uc77c\uc744 \uc77d\uc5b4 Pandas DataFrame\uc73c\ub85c \ubcc0\ud658\ud558\uace0 \uba54\ubaa8\ub9ac\uc5d0 \uc800\uc7a5\n",
    "    \n",
    "    Args:\n",
    "        url (str): CSV \ud30c\uc77c \uc8fc\uc18c\n",
    "        key (str): \uc800\uc7a5\ud560 \ud0a4\n",
    "        \n",
    "    Returns:\n",
    "        str: \uc791\uc5c5 \uacb0\uacfc \uba54\uc2dc\uc9c0\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "        data_storage[key] = df\n",
    "        return f\"CSV \ud30c\uc77c\uc774 \uc131\uacf5\uc801\uc73c\ub85c \ub85c\ub4dc\ub428 (\ud589: {len(df)}, \uc5f4: {len(df.columns)})\"\n",
    "    except Exception as e:\n",
    "        return f\"\uc624\ub958 \ubc1c\uc0dd: {str(e)}\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def show_df_stats(key: str) -> str:\n",
    "    \"\"\"\uc800\uc7a5\ub41c \ub370\uc774\ud130\ud504\ub808\uc784\uc758 \uae30\ubcf8 \ud1b5\uacc4 \uc815\ubcf4 \ucd9c\ub825\n",
    "    \uc800\uc7a5\ub41c \ub370\uc774\ud130 \ud615\ud0dc  (key) : Pandas DataFrame\n",
    "    \"\"\"\n",
    "    if key not in data_storage:\n",
    "        return \"\ud574\ub2f9 URL\uc758 CSV \ud30c\uc77c\uc744 \ucc3e\uc744 \uc218 \uc5c6\uc74c\"\n",
    "    \n",
    "    df = data_storage[key]\n",
    "    return f\"\"\"\n",
    "    \ud589 \uc218: {len(df)}\n",
    "    \uc5f4 \uc218: {len(df.columns)}\n",
    "    \uacb0\uce21\uce58 \uc218: {df.isnull().sum().sum()}\n",
    "    \uceec\ub7fc \ubaa9\ub85d: {df.columns.tolist()}\n",
    "    \uceec\ub7fc \ud0c0\uc785: {df.dtypes.to_dict()}\n",
    "    \uae30\ucd08 \ud1b5\uacc4: {df.describe().to_dict()}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def random_sample(key: str, n: int) -> str:\n",
    "    \"\"\"\uc800\uc7a5\ub41c \ub370\uc774\ud130\ud504\ub808\uc784\uc5d0\uc11c \ub79c\ub364 \uc0d8\ud50c \ucd94\ucd9c\n",
    "    \uc800\uc7a5\ub41c \ub370\uc774\ud130 \ud615\ud0dc  (key) : Pandas DataFrame\n",
    "    \"\"\"\n",
    "    if key not in data_storage:\n",
    "        return \"\ud574\ub2f9 URL\uc758 CSV \ud30c\uc77c\uc744 \ucc3e\uc744 \uc218 \uc5c6\uc74c\"\n",
    "    new_key = str(uuid.uuid4())\n",
    "    df = data_storage[key]\n",
    "    random_sample_df = df.sample(n)\n",
    "    data_storage[new_key] = random_sample_df\n",
    "    return f\"\ub79c\ub364 \uc0d8\ud50c \ucd94\ucd9c \uc644\ub8cc: (\uc800\uc7a5\uc18c key : {new_key})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def prep_df(key: str, target_column: str) -> str:\n",
    "    \"\"\"\uc800\uc7a5\ub41c \ub370\uc774\ud130\ud504\ub808\uc784\uc744 \uba38\uc2e0\ub7ec\ub2dd \ubaa8\ub378\uc5d0 \uc801\ud569\ud55c \ud615\ud0dc\ub85c \uc804\ucc98\ub9ac\n",
    "    \uc800\uc7a5\ub41c \ub370\uc774\ud130 \ud615\ud0dc  (key) : Pandas DataFrame\n",
    "    \uc0c8\ub85c \uc800\uc7a5\ud560 \ub370\uc774\ud130 \ud615\ud0dc (new_key) : (X, y) \ud615\ud0dc\uc758 \ud29c\ud50c\n",
    "    \"\"\"\n",
    "    new_key = str(uuid.uuid4())\n",
    "    df = data_storage[key]\n",
    "    if target_column not in df.columns:\n",
    "        return f\"\ud574\ub2f9 \uceec\ub7fc {target_column}\uc774 \uc874\uc7ac\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\"\n",
    "    df = df[df[target_column].notna()]\n",
    "    \n",
    "    # \uc2e4\uc218\ud615 \ub370\uc774\ud130\ub9cc \ub0a8\uae30\uae30\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    df = df[numeric_cols]\n",
    "    \n",
    "    if target_column not in df.columns:\n",
    "        return f\"\ud0c0\uac9f \uceec\ub7fc {target_column}\uc774 \uc2e4\uc218\ud615 \ub370\uc774\ud130\uac00 \uc544\ub2c8\uc5b4\uc11c \uc81c\uac70\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\"\n",
    "    \n",
    "    X = df.drop(target_column, axis=1)\n",
    "    y = df[target_column]\n",
    "    data_storage[new_key] = (X, y)\n",
    "    return f\"\ub370\uc774\ud130\ud504\ub808\uc784 \uc804\ucc98\ub9ac \uc644\ub8cc (\uc2e4\uc218\ud615 \ub370\uc774\ud130\ub9cc \ud3ec\ud568): (\uc800\uc7a5\uc18c key : {new_key})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def visualize_tsne(key: str) -> str:\n",
    "    \"\"\"\n",
    "    \uc800\uc7a5\ub41c \ub370\uc774\ud130\ud504\ub808\uc784\uc744 t-SNE\ub85c \uc2dc\uac01\ud654\n",
    "    \uc800\uc7a5\ub41c \ub370\uc774\ud130 \ud615\ud0dc (key) : (X, y) \ud615\ud0dc\uc758 \ud29c\ud50c\n",
    "    \uc0c8\ub85c \uc800\uc7a5\ud560 \ub370\uc774\ud130 \ud615\ud0dc (new_key) : Plotly \uac1d\uccb4\n",
    "    \"\"\"\n",
    "    from utils import TSNEVisualizer\n",
    "    import plotly.io as pio\n",
    "    from IPython.display import HTML\n",
    "    new_key = str(uuid.uuid4())\n",
    "    \n",
    "    # \ub80c\ub354\ub7ec \uc124\uc815\n",
    "    pio.renderers.default = \"notebook\"\n",
    "    \n",
    "    (X, y) = data_storage[key]\n",
    "    fig = TSNEVisualizer.visualize(X, y)\n",
    "    \n",
    "    # to_html \uba54\uc11c\ub4dc\ub85c HTML \ubb38\uc790\uc5f4 \uc0dd\uc131\ud558\uc5ec \ud45c\uc2dc\n",
    "    html_str = fig.to_html(include_plotlyjs='cdn')\n",
    "    display(HTML(html_str))\n",
    "    \n",
    "    data_storage[new_key] = fig\n",
    "    \n",
    "    return f\"t-SNE \uc2dc\uac01\ud654 \uc644\ub8cc: (\uc800\uc7a5\uc18c key : {new_key})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def kaggle_check_and_download_dataset(dataset_ref: str, path: str = None) -> str:\n",
    "    \"\"\"\n",
    "    \ub370\uc774\ud130\uc14b\uc774 \uc774\ubbf8 \ub2e4\uc6b4\ub85c\ub4dc\ub418\uc5b4 \uc788\ub294\uc9c0 \ud655\uc778\ud558\uace0, \uc5c6\uc73c\uba74 \ub2e4\uc6b4\ub85c\ub4dc\ud569\ub2c8\ub2e4.\n",
    "    \n",
    "    Args:\n",
    "        dataset_ref: \ub2e4\uc6b4\ub85c\ub4dc\ud560 \ub370\uc774\ud130\uc14b\uc758 \ucc38\uc870 (owner/dataset-name \ud615\uc2dd)\n",
    "        path: \ub370\uc774\ud130\uc14b\uc744 \uc800\uc7a5\ud560 \uacbd\ub85c (\uae30\ubcf8\uac12: None, Kaggle API \uae30\ubcf8 \uacbd\ub85c \uc0ac\uc6a9)\n",
    "    \n",
    "    Returns:\n",
    "        \ub370\uc774\ud130\uc14b \uc0c1\ud0dc \ubc0f \uacbd\ub85c \uc815\ubcf4\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "    \n",
    "    try:\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        \n",
    "        # \ub370\uc774\ud130\uc14b \uc815\ubcf4 \ucd94\ucd9c\n",
    "        owner, dataset_name = dataset_ref.split('/')\n",
    "        \n",
    "        # \uae30\ubcf8 Kaggle \ub2e4\uc6b4\ub85c\ub4dc \uacbd\ub85c \ub610\ub294 \uc0ac\uc6a9\uc790 \uc9c0\uc815 \uacbd\ub85c\n",
    "        if path is None:\n",
    "            from pathlib import Path\n",
    "            kaggle_dir = os.path.join(str(Path.home()), '.kaggle', 'datasets')\n",
    "            dataset_dir = os.path.join(kaggle_dir, owner, dataset_name)\n",
    "        else:\n",
    "            dataset_dir = os.path.join(path, owner, dataset_name)\n",
    "        \n",
    "        # \ub370\uc774\ud130\uc14b\uc774 \uc774\ubbf8 \uc874\uc7ac\ud558\ub294\uc9c0 \ud655\uc778\n",
    "        if os.path.exists(dataset_dir) and len(os.listdir(dataset_dir)) > 0:\n",
    "            # \ub370\uc774\ud130\uc14b\uc774 \uc774\ubbf8 \uc874\uc7ac\ud568\n",
    "            files = os.listdir(dataset_dir)\n",
    "            data_storage[dataset_ref] = dataset_dir\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"already_downloaded\": True,\n",
    "                \"message\": f\"\ub370\uc774\ud130\uc14b '{dataset_ref}'\ub294 \uc774\ubbf8 \ub2e4\uc6b4\ub85c\ub4dc\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.\",\n",
    "                \"path\": dataset_dir,\n",
    "                \"files\": files\n",
    "            }\n",
    "        else:\n",
    "            # \ub370\uc774\ud130\uc14b \ub2e4\uc6b4\ub85c\ub4dc\n",
    "            api.dataset_download_files(dataset_ref, path=path, unzip=True)\n",
    "            \n",
    "            # \ub2e4\uc6b4\ub85c\ub4dc \ud6c4 \uacbd\ub85c \ud655\uc778 \ubc0f \uc800\uc7a5\n",
    "            if path is None:\n",
    "                # \uae30\ubcf8 \uacbd\ub85c\uc5d0 \ub2e4\uc6b4\ub85c\ub4dc\ub41c \uacbd\uc6b0\n",
    "                dataset_dir = os.path.join(kaggle_dir, owner, dataset_name)\n",
    "            \n",
    "            if os.path.exists(dataset_dir):\n",
    "                files = os.listdir(dataset_dir)\n",
    "                data_storage[dataset_ref] = dataset_dir\n",
    "                \n",
    "                return {\n",
    "                    \"success\": True,\n",
    "                    \"already_downloaded\": False,\n",
    "                    \"message\": f\"\ub370\uc774\ud130\uc14b '{dataset_ref}'\ub97c \uc131\uacf5\uc801\uc73c\ub85c \ub2e4\uc6b4\ub85c\ub4dc\ud588\uc2b5\ub2c8\ub2e4.\",\n",
    "                    \"path\": dataset_dir,\n",
    "                    \"files\": files\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"message\": f\"\ub370\uc774\ud130\uc14b '{dataset_ref}'\ub97c \ub2e4\uc6b4\ub85c\ub4dc\ud588\uc9c0\ub9cc \uacbd\ub85c\ub97c \ucc3e\uc744 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4.\"\n",
    "                }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"message\": f\"\ub370\uc774\ud130\uc14b \ub2e4\uc6b4\ub85c\ub4dc \uc911 \uc624\ub958 \ubc1c\uc0dd: {str(e)}\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def under_resample(key: str) -> str:\n",
    "    \"\"\"\n",
    "    \uc800\uc7a5\ub41c \ub370\uc774\ud130\ud504\ub808\uc784\uc744 \uc5b8\ub354\ub9ac\uc0d8\ud50c\ub9c1\n",
    "    \uc800\uc7a5\ub41c \ub370\uc774\ud130 \ud615\ud0dc  (key) : (X, y) \ud615\ud0dc\uc758 \ud29c\ud50c\n",
    "    \uc0c8\ub85c \uc800\uc7a5\ud560 \ub370\uc774\ud130 \ud615\ud0dc (new_key) : (X, y) \ud615\ud0dc\uc758 \ud29c\ud50c\n",
    "    \"\"\"\n",
    "    from utils import ImbalancedDataAnalyzer\n",
    "    new_key = str(uuid.uuid4())\n",
    "    (X, y) = data_storage[key]\n",
    "    analyzer = ImbalancedDataAnalyzer(X, y)\n",
    "    X_resampled, y_resampled = analyzer.random_undersample()\n",
    "    data_storage[new_key] = (X_resampled, y_resampled)\n",
    "    return f\"SMOTE \ub9ac\uc0d8\ud50c\ub9c1 \uc644\ub8cc: (\uc800\uc7a5\uc18c key : {new_key})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def isolation_forest(key: str, contamination: float) -> str:\n",
    "    \"\"\"\n",
    "    \uc800\uc7a5\ub41c \ub370\uc774\ud130\ud504\ub808\uc784\uc744 Isolation Forest\ub85c \ubd84\uc11d\n",
    "    \uc800\uc7a5\ub41c \ub370\uc774\ud130 \ud615\ud0dc  (key) : (X, y) \ud615\ud0dc\uc758 \ud29c\ud50c\n",
    "    \uc0c8\ub85c \uc800\uc7a5\ud560 \ub370\uc774\ud130 \ud615\ud0dc (new_key) : (y, score) \ud615\ud0dc\uc758 \ud29c\ud50c\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    import plotly.express as px\n",
    "    new_key = str(uuid.uuid4())\n",
    "    \n",
    "    (X, y) = data_storage[key]\n",
    "    model = IsolationForest(contamination=contamination, max_samples=256)\n",
    "    model.fit(X)\n",
    "    score = model.score_samples(X)\n",
    "    score = -1 * score  # \uc774\ubd80\ubd84\uc784.\n",
    "    fig = px.histogram(x=score, nbins=100, labels={'x':'Score'}, title=\"\ud3c9\uac00\")\n",
    "    fig.update_layout(width=600, height=400)\n",
    "    fig.show()\n",
    "    data_storage[new_key] = (y, score)\n",
    "    return f\"Isolation Forest \ubd84\uc11d \uc644\ub8cc: (Score \uc800\uc7a5\uc18c key : {new_key})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def prec_rec_f1_curve(key: str):\n",
    "    \"\"\"\n",
    "    \uc800\uc7a5\ub41c \ub370\uc774\ud130\ud504\ub808\uc784\uc744 Precision, Recall, F1 Score \uace1\uc120\uc73c\ub85c \uc2dc\uac01\ud654\n",
    "    \uc800\uc7a5\ub41c \ub370\uc774\ud130 \ud615\ud0dc  (key) : (y, score) \ud615\ud0dc\uc758 \ud29c\ud50c\n",
    "    \uc0c8\ub85c \uc800\uc7a5\ud560 \ub370\uc774\ud130 \ud615\ud0dc (new_key) : (precision, recall, f1, thresholds) \ud615\ud0dc\uc758 \ud29c\ud50c\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import plotly.graph_objects as go\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    \n",
    "    new_key = str(uuid.uuid4())\n",
    "    y, score = data_storage[key]\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y, score, pos_label=1)\n",
    "    f1 = 2 / (1/precision + 1/recall)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=thresholds, y=np.delete(precision, -1), mode='lines', name='precision'))\n",
    "    fig.add_trace(go.Scatter(x=thresholds, y=np.delete(recall, -1), mode='lines', name='recall'))\n",
    "    fig.add_trace(go.Scatter(x=thresholds, y=np.delete(f1, -1), mode='lines', name='f1'))\n",
    "    fig.update_layout(title='Anomaly Score\uc5d0 \ub530\ub978 Precision, Recall, F1 Score',\n",
    "                      xaxis_title='Anomaly Score',\n",
    "                      yaxis_title='Score',\n",
    "                      legend_title='Score Type')\n",
    "    fig.show()\n",
    "    \n",
    "    data_storage[new_key] = (precision, recall, f1, thresholds)\n",
    "\n",
    "    return precision, recall, f1, thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def show_tool_list() -> str:\n",
    "    \"\"\"\n",
    "    \ud604\uc7ac \uc0ac\uc6a9 \uac00\ub2a5\ud55c \ub3c4\uad6c \ubaa9\ub85d\uc744 \ucd9c\ub825\n",
    "    \"\"\"\n",
    "    tool_names = [\n",
    "        \"show_tool_list\"\n",
    "        \"kaggle_list_datasets\",\n",
    "        \"kaggle_download_dataset\",\n",
    "        \"show_df_stats\",\n",
    "        \"random_sample\",\n",
    "        \"prep_df\",\n",
    "        \"visualize_tsne\",\n",
    "        \"under_resample\",\n",
    "        \"isolation_forest\",\n",
    "        \"prec_rec_f1_curve\",\n",
    "        \n",
    "    ]\n",
    "    return f\"\ud604\uc7ac \uc0ac\uc6a9 \uac00\ub2a5\ud55c \ub3c4\uad6c \ubaa9\ub85d: {', '.join(tool_names)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\n",
    "        \"\ub108\ub294 \ub370\uc774\ud130 \ubd84\uc11d \uc804\ubb38\uac00\uc57c\"\n",
    "        \"\uac00\ub2a5\ud55c \ud55c \ud56d\uc0c1 \uc81c\uacf5\ub41c \ub3c4\uad6c\ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc744 \uae30\uc5b5\ud574\uc57c\ub418.\"\n",
    "        \"\ub108\uac00 \uc0ac\uc6a9\uac00\ub2a5\ud55c \ub3c4\uad6c \ubaa9\ub85d\uc744 \uba3c\uc800 \ucd9c\ub825\ud574\ub193\uace0 \uc2dc\uc791\ud574. show_tool_list \ub3c4\uad6c\ub97c \uc0ac\uc6a9\ud558\uba74 \ub428.\"\n",
    "        \"\uc790\uc2e0\uc758 \uc9c0\uc2dd\uc5d0 \ub108\ubb34 \uc758\uc874\ud558\uc9c0 \ub9d0\uace0 \ub300\uc2e0 \uc9c8\ubb38\uc5d0 \ub2f5\ud558\ub294 \ub370 \ub3c4\uc6c0\uc774 \ub418\ub294 \ub3c4\uad6c\ub97c \uc0ac\uc6a9\ud558\uc138\uc694.\"\n",
    "        \"python \ucf54\ub4dc\ub97c \uc9c1\uc811\uad6c\ud604\ud558\ub294 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\uc9c0 \ub9d0\uace0, \ub3c4\uad6c\uc5d0 \uc758\uc874\ud558\uc138\uc694.\"\n",
    "        \"t-SNE \uc2dc\uac01\ud654\ub098 \ub2e4\ub978 \uc2dc\uac01\ud654\ub97c \uc0ac\uc6a9\ud560 \ub54c \uc0d8\ud50c \uc218\uac00 \uc801\uc5b4 'perplexity must be less than n_samples' \ub4f1\uc758 \uc624\ub958\uac00 \ubc1c\uc0dd\ud558\uba74, \"\n",
    "        \"\ud574\ub2f9 \uc2dc\uac01\ud654 \ub2e8\uacc4\ub97c \uac74\ub108\ub6f0\uace0 \uc0ac\uc6a9\uc790\uc5d0\uac8c \uc0d8\ud50c \uc218\uac00 \ubd80\uc871\ud558\uc5ec \uc2dc\uac01\ud654\uac00 \ubd88\uac00\ub2a5\ud558\ub2e4\uace0 \uc54c\ub824\uc8fc\uc138\uc694.\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[\n",
    "        show_tool_list,\n",
    "        kaggle_list_datasets,\n",
    "        kaggle_download_dataset,\n",
    "        show_df_stats,\n",
    "        random_sample,\n",
    "        prep_df,\n",
    "        visualize_tsne,\n",
    "        under_resample,\n",
    "        isolation_forest,\n",
    "        prec_rec_f1_curve,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \ud604\uc7ac \uc5d0\uc774\uc804\ud2b8: Assistant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error streaming response: Project `proj_9jPb3KpbTdfDPtpFQRloSjOo` does not have access to model `gpt-4o-mini-2024-07-18`\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "Project `proj_9jPb3KpbTdfDPtpFQRloSjOo` does not have access to model `gpt-4o-mini-2024-07-18`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# we do need to reinitialize our runner before re-executing\u001b[39;00m\n\u001b[32m      2\u001b[39m response = Runner.run_streamed(\n\u001b[32m      3\u001b[39m     starting_agent=agent,\n\u001b[32m      4\u001b[39m     \u001b[38;5;28minput\u001b[39m=\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m10. Isolation Forest \ubd84\uc11d\ud55c \ub370\uc774\ud130\ub97c Precision, Recall, F1 Score \uace1\uc120\uc73c\ub85c \uc2dc\uac01\ud654\ud574\uc918.\u001b[39m\u001b[33m\"\u001b[39m \n\u001b[32m     15\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m response.stream_events():\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m event.type == \u001b[33m\"\u001b[39m\u001b[33mraw_response_event\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     19\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event.data, ResponseFunctionCallArgumentsDeltaEvent):\n\u001b[32m     20\u001b[39m             \u001b[38;5;66;03m# \ub3c4\uad6c \ud638\ucd9c\uc744 \uc704\ud55c \uc2a4\ud2b8\ub9ac\ubc0d \ub9e4\uac1c\ubcc0\uc218\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/dante-code/projects/kmu-practical-ds-2025/.conda/lib/python3.12/site-packages/agents/result.py:205\u001b[39m, in \u001b[36mRunResultStreaming.stream_events\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28mself\u001b[39m._cleanup_tasks()\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stored_exception:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stored_exception\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/dante-code/projects/kmu-practical-ds-2025/.conda/lib/python3.12/site-packages/agents/run.py:560\u001b[39m, in \u001b[36mRunner._run_streamed_impl\u001b[39m\u001b[34m(cls, starting_input, streamed_result, starting_agent, max_turns, hooks, context_wrapper, run_config, previous_response_id)\u001b[39m\n\u001b[32m    549\u001b[39m     streamed_result._input_guardrails_task = asyncio.create_task(\n\u001b[32m    550\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_input_guardrails_with_queue(\n\u001b[32m    551\u001b[39m             starting_agent,\n\u001b[32m   (...)\u001b[39m\u001b[32m    557\u001b[39m         )\n\u001b[32m    558\u001b[39m     )\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._run_single_turn_streamed(\n\u001b[32m    561\u001b[39m         streamed_result,\n\u001b[32m    562\u001b[39m         current_agent,\n\u001b[32m    563\u001b[39m         hooks,\n\u001b[32m    564\u001b[39m         context_wrapper,\n\u001b[32m    565\u001b[39m         run_config,\n\u001b[32m    566\u001b[39m         should_run_agent_start_hooks,\n\u001b[32m    567\u001b[39m         tool_use_tracker,\n\u001b[32m    568\u001b[39m         all_tools,\n\u001b[32m    569\u001b[39m         previous_response_id,\n\u001b[32m    570\u001b[39m     )\n\u001b[32m    571\u001b[39m     should_run_agent_start_hooks = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    573\u001b[39m     streamed_result.raw_responses = streamed_result.raw_responses + [\n\u001b[32m    574\u001b[39m         turn_result.model_response\n\u001b[32m    575\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/dante-code/projects/kmu-practical-ds-2025/.conda/lib/python3.12/site-packages/agents/run.py:671\u001b[39m, in \u001b[36mRunner._run_single_turn_streamed\u001b[39m\u001b[34m(cls, streamed_result, agent, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, all_tools, previous_response_id)\u001b[39m\n\u001b[32m    668\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m streamed_result.new_items])\n\u001b[32m    670\u001b[39m \u001b[38;5;66;03m# 1. Stream the output events\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m model.stream_response(\n\u001b[32m    672\u001b[39m     system_prompt,\n\u001b[32m    673\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    674\u001b[39m     model_settings,\n\u001b[32m    675\u001b[39m     all_tools,\n\u001b[32m    676\u001b[39m     output_schema,\n\u001b[32m    677\u001b[39m     handoffs,\n\u001b[32m    678\u001b[39m     get_model_tracing_impl(\n\u001b[32m    679\u001b[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001b[32m    680\u001b[39m     ),\n\u001b[32m    681\u001b[39m     previous_response_id=previous_response_id,\n\u001b[32m    682\u001b[39m ):\n\u001b[32m    683\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, ResponseCompletedEvent):\n\u001b[32m    684\u001b[39m         usage = (\n\u001b[32m    685\u001b[39m             Usage(\n\u001b[32m    686\u001b[39m                 requests=\u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    692\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m Usage()\n\u001b[32m    693\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/dante-code/projects/kmu-practical-ds-2025/.conda/lib/python3.12/site-packages/agents/models/openai_responses.py:157\u001b[39m, in \u001b[36mOpenAIResponsesModel.stream_response\u001b[39m\u001b[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id)\u001b[39m\n\u001b[32m    144\u001b[39m stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fetch_response(\n\u001b[32m    145\u001b[39m     system_instructions,\n\u001b[32m    146\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    152\u001b[39m     stream=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    153\u001b[39m )\n\u001b[32m    155\u001b[39m final_response: Response | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunk, ResponseCompletedEvent):\n\u001b[32m    159\u001b[39m         final_response = chunk.response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/dante-code/projects/kmu-practical-ds-2025/.conda/lib/python3.12/site-packages/openai/_streaming.py:147\u001b[39m, in \u001b[36mAsyncStream.__aiter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aiter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> AsyncIterator[_T]:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator:\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/dante-code/projects/kmu-practical-ds-2025/.conda/lib/python3.12/site-packages/openai/_streaming.py:193\u001b[39m, in \u001b[36mAsyncStream.__stream__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    190\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m message \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    191\u001b[39m                 message = \u001b[33m\"\u001b[39m\u001b[33mAn error occurred during streaming\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m APIError(\n\u001b[32m    194\u001b[39m                 message=message,\n\u001b[32m    195\u001b[39m                 request=\u001b[38;5;28mself\u001b[39m.response.request,\n\u001b[32m    196\u001b[39m                 body=data[\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    197\u001b[39m             )\n\u001b[32m    199\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m process_data(data={\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m: data, \u001b[33m\"\u001b[39m\u001b[33mevent\u001b[39m\u001b[33m\"\u001b[39m: sse.event}, cast_to=cast_to, response=response)\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# Ensure the entire stream is consumed\u001b[39;00m\n",
      "\u001b[31mAPIError\u001b[39m: Project `proj_9jPb3KpbTdfDPtpFQRloSjOo` does not have access to model `gpt-4o-mini-2024-07-18`"
     ]
    }
   ],
   "source": [
    "# we do need to reinitialize our runner before re-executing\n",
    "response = Runner.run_streamed(\n",
    "    starting_agent=agent,\n",
    "    input=\n",
    "        \"1. \uc0ac\uae30 \uc774\uc0c1\ud0d0\uc9c0 \uad00\ub828 \ub370\uc774\ud130\uc14b\uc744 \uce90\uae00\uc5d0\uc11c \uc870\ud68c\ud55c\ud6c4,\"\n",
    "        \"2. \uccab\ubc88\uc9f8 \ub370\uc774\ud130\uc14b\uc744 \ub2e4\uc6b4\ub85c\ub4dc\ud574\uc918.\"\n",
    "        \"3. \ub2e4\uc6b4\ub85c\ub4dc \ubc1b\uc740 \ub370\uc774\ud130\uc14b\uc5d0\uc11c 3000\uac1c \ub808\ucf54\ub4dc\ub9cc \ub79c\ub364 \uc0d8\ud50c\ub9c1\ud574\uc918.\"\n",
    "        \"4. 3000\uac1c \ub808\ucf54\ub4dc\uc758 \uae30\ucd08 \ud1b5\uacc4\ub7c9\uc744 \ucd9c\ub825\ud574\uc918.\"\n",
    "        \"5. \uc55e\uc5d0\uc11c \ucc98\ub9ac\ud55c \ub79c\ub364 \uc0d8\ud50c\ub9c1\ud55c 3000\uac1c \ub808\ucf54\ub4dc\ub97c \uba38\uc2e0\ub7ec\ub2dd \ubaa8\ub378\uc5d0 \uc801\ud569\ud55c \ud615\ud0dc\ub85c \uc804\ucc98\ub9ac\ud574\uc918.\"\n",
    "        \"6. \uc804\ucc98\ub9ac\ud55c \ub370\uc774\ud130\ub97c TSNE \uc2dc\uac01\ud654\ud574\uc918.\"\n",
    "        \"7. \uc804\ucc98\ub9ac\ud55c \ub370\uc774\ud130\ub97c SMOTE \ub9ac\uc0d8\ud50c\ub9c1\uc744 \ud574\uc918.\"\n",
    "        \"8. SMOTE \ub9ac\uc0d8\ud50c\ub9c1\ud55c \ub370\uc774\ud130\ub97c TSNE \uc2dc\uac01\ud654\ud574\uc918.\"\n",
    "        \"9. SMOTE \ub9ac\uc0d8\ud50c\ub9c1\ud55c \ub370\uc774\ud130\ub97c Isolation Forest \ubd84\uc11d\ud574\uc918.\"\n",
    "        \"10. Isolation Forest \ubd84\uc11d\ud55c \ub370\uc774\ud130\ub97c Precision, Recall, F1 Score \uace1\uc120\uc73c\ub85c \uc2dc\uac01\ud654\ud574\uc918.\" \n",
    ")\n",
    "\n",
    "async for event in response.stream_events():\n",
    "    if event.type == \"raw_response_event\":\n",
    "        if isinstance(event.data, ResponseFunctionCallArgumentsDeltaEvent):\n",
    "            # \ub3c4\uad6c \ud638\ucd9c\uc744 \uc704\ud55c \uc2a4\ud2b8\ub9ac\ubc0d \ub9e4\uac1c\ubcc0\uc218\n",
    "            print(event.data.delta, end=\"\", flush=True)\n",
    "        elif isinstance(event.data, ResponseTextDeltaEvent):\n",
    "            # \uc2a4\ud2b8\ub9ac\ubc0d\ub41c \ucd5c\uc885 \uc751\ub2f5 \ud1a0\ud070\n",
    "            print(event.data.delta, end=\"\", flush=True)\n",
    "    elif event.type == \"agent_updated_stream_event\":\n",
    "        # \ud604\uc7ac \uc0ac\uc6a9 \uc911\uc778 \uc5d0\uc774\uc804\ud2b8 \uc815\ubcf4\n",
    "        print(f\"> \ud604\uc7ac \uc5d0\uc774\uc804\ud2b8: {event.new_agent.name}\")\n",
    "    elif event.type == \"run_item_stream_event\":\n",
    "        # \uc0ac\uc6a9\uc790\ub098 \ub2e4\uc6b4\uc2a4\ud2b8\ub9bc \ud504\ub85c\uc138\uc2a4\ub85c \uc2a4\ud2b8\ub9ac\ubc0d\ud560 \uc815\ubcf4\ub97c \ud3ec\ud568\ud558\ub294 \uc774\ubca4\ud2b8\n",
    "        if event.name == \"tool_called\":\n",
    "            # \ubaa8\ub4e0 \ub3c4\uad6c \ud1a0\ud070\uc774 \uc2a4\ud2b8\ub9ac\ubc0d\ub41c \ud6c4 \uc804\uccb4 \ub3c4\uad6c \ud638\ucd9c \uc815\ubcf4\n",
    "            print()\n",
    "            print(f\"> \ub3c4\uad6c \ud638\ucd9c\ub428, \uc774\ub984: {event.item.raw_item.name}\")\n",
    "            print(f\"> \ub3c4\uad6c \ud638\ucd9c\ub428, \uc778\uc790: {event.item.raw_item.arguments}\")\n",
    "        elif event.name == \"tool_output\":\n",
    "            # \ub3c4\uad6c \uc2e4\ud589 \uacb0\uacfc\n",
    "            print(f\"> \ub3c4\uad6c \ucd9c\ub825: {event.item.raw_item['output']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_storage.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_storage['e979a416-372c-4766-8a37-8189f4ba7d49']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}